{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './assets/diabetes.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
       "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
       "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
       "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
       "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
       "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
       "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
       "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
       "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
       "Glucose                   0.331357  0.221071                  0.137337   \n",
       "BloodPressure             0.088933  0.281805                  0.041265   \n",
       "SkinThickness             0.436783  0.392573                  0.183928   \n",
       "Insulin                   1.000000  0.197859                  0.185071   \n",
       "BMI                       0.197859  1.000000                  0.140647   \n",
       "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
       "Age                      -0.042163  0.036242                  0.033561   \n",
       "Outcome                   0.130548  0.292695                  0.173844   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.544341  0.221898  \n",
       "Glucose                   0.263514  0.466581  \n",
       "BloodPressure             0.239528  0.065068  \n",
       "SkinThickness            -0.113970  0.074752  \n",
       "Insulin                  -0.042163  0.130548  \n",
       "BMI                       0.036242  0.292695  \n",
       "DiabetesPedigreeFunction  0.033561  0.173844  \n",
       "Age                       1.000000  0.238356  \n",
       "Outcome                   0.238356  1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['BloodPressure', 'SkinThickness', 'Insulin'] #removing columns with low correlation with outcome\n",
    "\n",
    "df = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k = 5\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=X_train_selected.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Coding_Dev\\College\\SEM_6\\neural-networks-niit\\Lab_7.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# model.fit(X_train, y_train, epochs=100)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9qi2n2h6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\barar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=60, verbose=2)\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Coding_Dev\\College\\SEM_6\\neural-networks-niit\\Lab_7.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m selector \u001b[39m=\u001b[39m SelectKBest(score_func\u001b[39m=\u001b[39mchi2, k\u001b[39m=\u001b[39mk)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mfit_transform(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Coding_Dev/College/SEM_6/neural-networks-niit/Lab_7.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m16\u001b[39m, input_dim\u001b[39m=\u001b[39mX_train_selected\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:503\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    498\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    499\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m], multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    500\u001b[0m )\n\u001b[0;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X, y)\n\u001b[1;32m--> 503\u001b[0m score_func_ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_func(X, y)\n\u001b[0;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(score_func_ret, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscores_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpvalues_ \u001b[39m=\u001b[39m score_func_ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:231\u001b[0m, in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m(np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32))\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many((X\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(X) \u001b[39melse\u001b[39;00m X) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput X must be non-negative.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[39m# Use a sparse representation for Y by default to reduce memory usage when\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39m# y has many unique classes.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m Y \u001b[39m=\u001b[39m LabelBinarizer(sparse_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mfit_transform(y)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "k = 5\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=X_train_selected.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_selected, y_train, epochs=100, batch_size=50, verbose=2)\n",
    "\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy on test set: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17793 (69.50 KB)\n",
      "Trainable params: 17793 (69.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "16/16 - 1s - loss: 0.6246 - accuracy: 0.6293 - val_loss: 0.5847 - val_accuracy: 0.6992 - 1s/epoch - 72ms/step\n",
      "Epoch 2/75\n",
      "16/16 - 0s - loss: 0.5049 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7317 - 76ms/epoch - 5ms/step\n",
      "Epoch 3/75\n",
      "16/16 - 0s - loss: 0.4642 - accuracy: 0.7800 - val_loss: 0.4801 - val_accuracy: 0.7642 - 70ms/epoch - 4ms/step\n",
      "Epoch 4/75\n",
      "16/16 - 0s - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4698 - val_accuracy: 0.7642 - 70ms/epoch - 4ms/step\n",
      "Epoch 5/75\n",
      "16/16 - 0s - loss: 0.4306 - accuracy: 0.7902 - val_loss: 0.4711 - val_accuracy: 0.7561 - 71ms/epoch - 4ms/step\n",
      "Epoch 6/75\n",
      "16/16 - 0s - loss: 0.4209 - accuracy: 0.8045 - val_loss: 0.4699 - val_accuracy: 0.7398 - 79ms/epoch - 5ms/step\n",
      "Epoch 7/75\n",
      "16/16 - 0s - loss: 0.4162 - accuracy: 0.7984 - val_loss: 0.4702 - val_accuracy: 0.7480 - 83ms/epoch - 5ms/step\n",
      "Epoch 8/75\n",
      "16/16 - 0s - loss: 0.4113 - accuracy: 0.7984 - val_loss: 0.4672 - val_accuracy: 0.7398 - 81ms/epoch - 5ms/step\n",
      "Epoch 9/75\n",
      "16/16 - 0s - loss: 0.4072 - accuracy: 0.8065 - val_loss: 0.4702 - val_accuracy: 0.7561 - 104ms/epoch - 7ms/step\n",
      "Epoch 10/75\n",
      "16/16 - 0s - loss: 0.4015 - accuracy: 0.8126 - val_loss: 0.4772 - val_accuracy: 0.7642 - 73ms/epoch - 5ms/step\n",
      "Epoch 11/75\n",
      "16/16 - 0s - loss: 0.4040 - accuracy: 0.8147 - val_loss: 0.4700 - val_accuracy: 0.7561 - 77ms/epoch - 5ms/step\n",
      "Epoch 12/75\n",
      "16/16 - 0s - loss: 0.3950 - accuracy: 0.8086 - val_loss: 0.4722 - val_accuracy: 0.7317 - 81ms/epoch - 5ms/step\n",
      "Epoch 13/75\n",
      "16/16 - 0s - loss: 0.3889 - accuracy: 0.8248 - val_loss: 0.4724 - val_accuracy: 0.7480 - 69ms/epoch - 4ms/step\n",
      "Epoch 14/75\n",
      "16/16 - 0s - loss: 0.3934 - accuracy: 0.8208 - val_loss: 0.4755 - val_accuracy: 0.7642 - 69ms/epoch - 4ms/step\n",
      "Epoch 15/75\n",
      "16/16 - 0s - loss: 0.3862 - accuracy: 0.8208 - val_loss: 0.4733 - val_accuracy: 0.7561 - 69ms/epoch - 4ms/step\n",
      "Epoch 16/75\n",
      "16/16 - 0s - loss: 0.3778 - accuracy: 0.8228 - val_loss: 0.4766 - val_accuracy: 0.7642 - 87ms/epoch - 5ms/step\n",
      "Epoch 17/75\n",
      "16/16 - 0s - loss: 0.3765 - accuracy: 0.8208 - val_loss: 0.4794 - val_accuracy: 0.7561 - 77ms/epoch - 5ms/step\n",
      "Epoch 18/75\n",
      "16/16 - 0s - loss: 0.3718 - accuracy: 0.8289 - val_loss: 0.4711 - val_accuracy: 0.7561 - 71ms/epoch - 4ms/step\n",
      "Epoch 19/75\n",
      "16/16 - 0s - loss: 0.3695 - accuracy: 0.8350 - val_loss: 0.4804 - val_accuracy: 0.7561 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/75\n",
      "16/16 - 0s - loss: 0.3649 - accuracy: 0.8350 - val_loss: 0.4767 - val_accuracy: 0.7561 - 70ms/epoch - 4ms/step\n",
      "Epoch 21/75\n",
      "16/16 - 0s - loss: 0.3629 - accuracy: 0.8330 - val_loss: 0.4752 - val_accuracy: 0.7561 - 69ms/epoch - 4ms/step\n",
      "Epoch 22/75\n",
      "16/16 - 0s - loss: 0.3587 - accuracy: 0.8269 - val_loss: 0.4796 - val_accuracy: 0.7480 - 76ms/epoch - 5ms/step\n",
      "Epoch 23/75\n",
      "16/16 - 0s - loss: 0.3586 - accuracy: 0.8391 - val_loss: 0.4806 - val_accuracy: 0.7561 - 76ms/epoch - 5ms/step\n",
      "Epoch 24/75\n",
      "16/16 - 0s - loss: 0.3493 - accuracy: 0.8473 - val_loss: 0.4822 - val_accuracy: 0.7480 - 69ms/epoch - 4ms/step\n",
      "Epoch 25/75\n",
      "16/16 - 0s - loss: 0.3502 - accuracy: 0.8473 - val_loss: 0.4823 - val_accuracy: 0.7561 - 73ms/epoch - 5ms/step\n",
      "Epoch 26/75\n",
      "16/16 - 0s - loss: 0.3462 - accuracy: 0.8493 - val_loss: 0.4794 - val_accuracy: 0.7642 - 85ms/epoch - 5ms/step\n",
      "Epoch 27/75\n",
      "16/16 - 0s - loss: 0.3388 - accuracy: 0.8493 - val_loss: 0.4856 - val_accuracy: 0.7805 - 69ms/epoch - 4ms/step\n",
      "Epoch 28/75\n",
      "16/16 - 0s - loss: 0.3396 - accuracy: 0.8493 - val_loss: 0.4764 - val_accuracy: 0.7642 - 74ms/epoch - 5ms/step\n",
      "Epoch 29/75\n",
      "16/16 - 0s - loss: 0.3336 - accuracy: 0.8554 - val_loss: 0.4859 - val_accuracy: 0.7642 - 76ms/epoch - 5ms/step\n",
      "Epoch 30/75\n",
      "16/16 - 0s - loss: 0.3409 - accuracy: 0.8493 - val_loss: 0.4838 - val_accuracy: 0.7642 - 68ms/epoch - 4ms/step\n",
      "Epoch 31/75\n",
      "16/16 - 0s - loss: 0.3323 - accuracy: 0.8574 - val_loss: 0.4755 - val_accuracy: 0.7642 - 76ms/epoch - 5ms/step\n",
      "Epoch 32/75\n",
      "16/16 - 0s - loss: 0.3241 - accuracy: 0.8534 - val_loss: 0.4883 - val_accuracy: 0.7561 - 69ms/epoch - 4ms/step\n",
      "Epoch 33/75\n",
      "16/16 - 0s - loss: 0.3220 - accuracy: 0.8574 - val_loss: 0.4915 - val_accuracy: 0.7317 - 72ms/epoch - 5ms/step\n",
      "Epoch 34/75\n",
      "16/16 - 0s - loss: 0.3219 - accuracy: 0.8676 - val_loss: 0.4852 - val_accuracy: 0.7480 - 75ms/epoch - 5ms/step\n",
      "Epoch 35/75\n",
      "16/16 - 0s - loss: 0.3174 - accuracy: 0.8635 - val_loss: 0.4943 - val_accuracy: 0.7480 - 98ms/epoch - 6ms/step\n",
      "Epoch 36/75\n",
      "16/16 - 0s - loss: 0.3114 - accuracy: 0.8697 - val_loss: 0.4828 - val_accuracy: 0.7642 - 71ms/epoch - 4ms/step\n",
      "Epoch 37/75\n",
      "16/16 - 0s - loss: 0.3110 - accuracy: 0.8859 - val_loss: 0.5031 - val_accuracy: 0.7642 - 112ms/epoch - 7ms/step\n",
      "Epoch 38/75\n",
      "16/16 - 0s - loss: 0.3076 - accuracy: 0.8717 - val_loss: 0.4884 - val_accuracy: 0.7561 - 106ms/epoch - 7ms/step\n",
      "Epoch 39/75\n",
      "16/16 - 0s - loss: 0.3014 - accuracy: 0.8819 - val_loss: 0.4939 - val_accuracy: 0.7642 - 68ms/epoch - 4ms/step\n",
      "Epoch 40/75\n",
      "16/16 - 0s - loss: 0.2967 - accuracy: 0.8798 - val_loss: 0.4863 - val_accuracy: 0.7480 - 68ms/epoch - 4ms/step\n",
      "Epoch 41/75\n",
      "16/16 - 0s - loss: 0.2958 - accuracy: 0.8778 - val_loss: 0.5079 - val_accuracy: 0.7561 - 75ms/epoch - 5ms/step\n",
      "Epoch 42/75\n",
      "16/16 - 0s - loss: 0.2923 - accuracy: 0.8921 - val_loss: 0.4977 - val_accuracy: 0.7480 - 72ms/epoch - 5ms/step\n",
      "Epoch 43/75\n",
      "16/16 - 0s - loss: 0.2842 - accuracy: 0.8880 - val_loss: 0.4998 - val_accuracy: 0.7480 - 73ms/epoch - 5ms/step\n",
      "Epoch 44/75\n",
      "16/16 - 0s - loss: 0.2805 - accuracy: 0.8941 - val_loss: 0.5054 - val_accuracy: 0.7480 - 74ms/epoch - 5ms/step\n",
      "Epoch 45/75\n",
      "16/16 - 0s - loss: 0.2826 - accuracy: 0.8819 - val_loss: 0.5085 - val_accuracy: 0.7480 - 74ms/epoch - 5ms/step\n",
      "Epoch 46/75\n",
      "16/16 - 0s - loss: 0.2832 - accuracy: 0.8819 - val_loss: 0.5047 - val_accuracy: 0.7398 - 71ms/epoch - 4ms/step\n",
      "Epoch 47/75\n",
      "16/16 - 0s - loss: 0.2823 - accuracy: 0.8758 - val_loss: 0.5242 - val_accuracy: 0.7398 - 72ms/epoch - 4ms/step\n",
      "Epoch 48/75\n",
      "16/16 - 0s - loss: 0.2693 - accuracy: 0.8880 - val_loss: 0.5044 - val_accuracy: 0.7561 - 72ms/epoch - 4ms/step\n",
      "Epoch 49/75\n",
      "16/16 - 0s - loss: 0.2673 - accuracy: 0.8859 - val_loss: 0.5097 - val_accuracy: 0.7561 - 70ms/epoch - 4ms/step\n",
      "Epoch 50/75\n",
      "16/16 - 0s - loss: 0.2645 - accuracy: 0.8982 - val_loss: 0.5236 - val_accuracy: 0.7805 - 106ms/epoch - 7ms/step\n",
      "Epoch 51/75\n",
      "16/16 - 0s - loss: 0.2617 - accuracy: 0.9022 - val_loss: 0.5200 - val_accuracy: 0.7317 - 105ms/epoch - 7ms/step\n",
      "Epoch 52/75\n",
      "16/16 - 0s - loss: 0.2567 - accuracy: 0.9063 - val_loss: 0.5374 - val_accuracy: 0.7642 - 72ms/epoch - 5ms/step\n",
      "Epoch 53/75\n",
      "16/16 - 0s - loss: 0.2615 - accuracy: 0.9043 - val_loss: 0.5302 - val_accuracy: 0.7480 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/75\n",
      "16/16 - 0s - loss: 0.2536 - accuracy: 0.9022 - val_loss: 0.5313 - val_accuracy: 0.7480 - 71ms/epoch - 4ms/step\n",
      "Epoch 55/75\n",
      "16/16 - 0s - loss: 0.2479 - accuracy: 0.9043 - val_loss: 0.5383 - val_accuracy: 0.7398 - 67ms/epoch - 4ms/step\n",
      "Epoch 56/75\n",
      "16/16 - 0s - loss: 0.2494 - accuracy: 0.8941 - val_loss: 0.5375 - val_accuracy: 0.7561 - 71ms/epoch - 4ms/step\n",
      "Epoch 57/75\n",
      "16/16 - 0s - loss: 0.2440 - accuracy: 0.9124 - val_loss: 0.5357 - val_accuracy: 0.7642 - 73ms/epoch - 5ms/step\n",
      "Epoch 58/75\n",
      "16/16 - 0s - loss: 0.2373 - accuracy: 0.9063 - val_loss: 0.5354 - val_accuracy: 0.7398 - 72ms/epoch - 5ms/step\n",
      "Epoch 59/75\n",
      "16/16 - 0s - loss: 0.2360 - accuracy: 0.9043 - val_loss: 0.5486 - val_accuracy: 0.7236 - 97ms/epoch - 6ms/step\n",
      "Epoch 60/75\n",
      "16/16 - 0s - loss: 0.2336 - accuracy: 0.9185 - val_loss: 0.5275 - val_accuracy: 0.7561 - 67ms/epoch - 4ms/step\n",
      "Epoch 61/75\n",
      "16/16 - 0s - loss: 0.2242 - accuracy: 0.9287 - val_loss: 0.5525 - val_accuracy: 0.7398 - 71ms/epoch - 4ms/step\n",
      "Epoch 62/75\n",
      "16/16 - 0s - loss: 0.2220 - accuracy: 0.9165 - val_loss: 0.5583 - val_accuracy: 0.7480 - 116ms/epoch - 7ms/step\n",
      "Epoch 63/75\n",
      "16/16 - 0s - loss: 0.2280 - accuracy: 0.9165 - val_loss: 0.5613 - val_accuracy: 0.7724 - 108ms/epoch - 7ms/step\n",
      "Epoch 64/75\n",
      "16/16 - 0s - loss: 0.2157 - accuracy: 0.9328 - val_loss: 0.5698 - val_accuracy: 0.7398 - 67ms/epoch - 4ms/step\n",
      "Epoch 65/75\n",
      "16/16 - 0s - loss: 0.2117 - accuracy: 0.9287 - val_loss: 0.5696 - val_accuracy: 0.7317 - 71ms/epoch - 4ms/step\n",
      "Epoch 66/75\n",
      "16/16 - 0s - loss: 0.2079 - accuracy: 0.9267 - val_loss: 0.5722 - val_accuracy: 0.7561 - 86ms/epoch - 5ms/step\n",
      "Epoch 67/75\n",
      "16/16 - 0s - loss: 0.2058 - accuracy: 0.9348 - val_loss: 0.5879 - val_accuracy: 0.7561 - 74ms/epoch - 5ms/step\n",
      "Epoch 68/75\n",
      "16/16 - 0s - loss: 0.2001 - accuracy: 0.9389 - val_loss: 0.5945 - val_accuracy: 0.7398 - 79ms/epoch - 5ms/step\n",
      "Epoch 69/75\n",
      "16/16 - 0s - loss: 0.2017 - accuracy: 0.9348 - val_loss: 0.5744 - val_accuracy: 0.7805 - 75ms/epoch - 5ms/step\n",
      "Epoch 70/75\n",
      "16/16 - 0s - loss: 0.1980 - accuracy: 0.9226 - val_loss: 0.5955 - val_accuracy: 0.7642 - 75ms/epoch - 5ms/step\n",
      "Epoch 71/75\n",
      "16/16 - 0s - loss: 0.1957 - accuracy: 0.9328 - val_loss: 0.5949 - val_accuracy: 0.7317 - 87ms/epoch - 5ms/step\n",
      "Epoch 72/75\n",
      "16/16 - 0s - loss: 0.1976 - accuracy: 0.9348 - val_loss: 0.6095 - val_accuracy: 0.7398 - 69ms/epoch - 4ms/step\n",
      "Epoch 73/75\n",
      "16/16 - 0s - loss: 0.1874 - accuracy: 0.9409 - val_loss: 0.5911 - val_accuracy: 0.7642 - 103ms/epoch - 6ms/step\n",
      "Epoch 74/75\n",
      "16/16 - 0s - loss: 0.1814 - accuracy: 0.9552 - val_loss: 0.5990 - val_accuracy: 0.7480 - 93ms/epoch - 6ms/step\n",
      "Epoch 75/75\n",
      "16/16 - 0s - loss: 0.1782 - accuracy: 0.9511 - val_loss: 0.6162 - val_accuracy: 0.7480 - 68ms/epoch - 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"./assets/diabetes.csv\")\n",
    "\n",
    "X = df.iloc[:,:-1] \n",
    "#X = df[['Pregnancies', 'BMI', 'Insulin', 'Age']] \n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=75, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "classification_report_str = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "#print('Classification Report:\\n', classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
